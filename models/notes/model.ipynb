{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "CLR = {\n",
    "    'blue': ['#e0f3ff', '#aadeff', '#2bb1ff', '#15587f', '#0b2c40'],\n",
    "    'gold': ['#fff3dc', '#ffebc7', '#ffddab', '#b59d79', '#5C4938'],\n",
    "    'red':  ['#ffd8e8', '#ff9db6', '#ff3e72', '#6B404C', '#521424'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ungol.embcompr as ue\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "\n",
    "import pathlib\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cluster_distances(compressor: ue.Compressor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate the distance for each codebook vector to the codebook vector's\n",
    "    cluster center and then the respective distances of each cluster to another.\n",
    "    \n",
    "    M is the number of codebooks.\n",
    "    \n",
    "    Returns:\n",
    "        -- vector distances: (M, ) shaped tensor (distance of the codebook vectors to cluster center)\n",
    "        -- cluster distances: (M, M) shaped tensor (distance of each cluster center to all others)\n",
    "    \n",
    "    \"\"\"\n",
    "    dims = compressor.dimensions\n",
    "    M, K, E = dims.components, dims.codelength, dims.embedding\n",
    "    codebooks = compressor.decoder.components.view(M, K, E)\n",
    "\n",
    "    # calculate the center of codebook clusters\n",
    "    clusters = codebooks.sum(dim=1) / K\n",
    "    assert clusters.shape[0] == M\n",
    "\n",
    "    # calculate the distance of the first codebook vector\n",
    "    # to its codebook cluster center. As all codebook vectors\n",
    "    # are equidistant to the cluster center, this sampling is sufficient.\n",
    "    # vec_dists.shape -> (M, )\n",
    "    vector_dists = (clusters - codebooks[:, 0, :]).abs().norm(dim=-1)\n",
    "    assert vector_dists.shape[0] == M\n",
    "\n",
    "    # calculate the distance of each cluster center to all other\n",
    "    # cluster centers, stack repeated cluster vectors and all clusters\n",
    "    # cluster_dists.shape -> (M, M)\n",
    "    centers = torch.stack([cluster.expand(M, -1) for cluster in clusters])\n",
    "    cluster_dists = (centers - clusters.expand(M, M, -1)).abs().norm(dim=-1)\n",
    "\n",
    "    assert cluster_dists.shape[0] == cluster_dists.shape[1]\n",
    "    assert cluster_dists.diag().sum().item() == 0\n",
    "    \n",
    "    return vector_dists.detach(), cluster_dists.detach()\n",
    "\n",
    "\n",
    "def agg_cluster_distances(compressor: ue.Compressor, cutoff: int = 10, display: bool = True, save: bool = False):\n",
    "    M = compressor.dimensions.components\n",
    "    vec_dists, cluster_dists = cluster_distances(compressor)\n",
    "    aggregated_data = list(zip(range(1, M + 1), vec_dists, cluster_dists.mean(dim=-1)))\n",
    "\n",
    "    title = ''.join(['\\n\\n', '-' * 60, '\\n', glob.parts[-3], ' (', glob.name, ')'])\n",
    "    sbuf = [title, 'mean distance:']\n",
    "    \n",
    "    sbuf.append('  vectors: {:2.3f} (std={:2.3f})'.format(\n",
    "        vec_dists.mean().item(), \n",
    "        vec_dists.std().item(), ))\n",
    "    \n",
    "    sbuf.append('  cluster: {:2.3f} (std={:2.3f})'.format(\n",
    "        cluster_dists.mean().item(), \n",
    "        cluster_dists.std().item(), ))\n",
    "        \n",
    "    sbuf.append('')\n",
    "\n",
    "    sbuf.append(tabulate(\n",
    "        aggregated_data[:min(cutoff, M)],\n",
    "        headers=('codebook', 'vector dist', 'mean cluster dist')))\n",
    "    \n",
    "    return '\\n'.join(sbuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_scatter(compressor: ue.Compressor, path: pathlib.Path, display: bool = True, save: bool = False):\n",
    "    dims = compressor.dimensions\n",
    "    M, K = dims.components, dims.codelength\n",
    "    \n",
    "    codebooks = compressor.decoder.components.detach().numpy()\n",
    "    \n",
    "    dt = np.dtype([('color', np.unicode_, 7)])\n",
    "    clr = np.array([CLR['blue'][2], CLR['gold'][2], CLR['red'][2]], dtype=dt)\n",
    "\n",
    "    # create color map\n",
    "    base_cmap = clr.repeat(K).reshape(-1, K)\n",
    "    cmap = [c[0] for c in base_cmap.flat]\n",
    "    \n",
    "    # gesundheit\n",
    "    sne = manifold.TSNE(n_components=2)\n",
    "    arr = sne.fit_transform(codebooks)\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    folder = path.parents[0]\n",
    "    ax.set_title('Codebook Vectors ({})'.format(folder.parents[0].parts[-1].replace('-', '/')))\n",
    "    ax.scatter(arr[:, 0], arr[:, 1], color=cmap, marker='.', alpha=0.5)\n",
    "    \n",
    "    if save:\n",
    "        img_folder = folder.parents[0] / 'images'\n",
    "        img_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        fname = str(img_folder / ('codebooks_' + path.stem.split('-')[-1]))\n",
    "        fig.savefig(fname + '.png')\n",
    "        fig.savefig(fname + '.svg')\n",
    "        # print('saving images to {}*'.format(fname))\n",
    "    \n",
    "    if display:\n",
    "        plt.show(fig)\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play the organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, '\"run all\" shall not pass!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print tables and t-SNE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    display=False,\n",
    "    save=True, )\n",
    "\n",
    "experiment = 'tau'\n",
    "embedding = 'glove'\n",
    "\n",
    "# ---\n",
    "\n",
    "f_base = '../opt/experiments'\n",
    "f_glob = experiment + '/' + embedding + '-*/compressor/model-*.torch'\n",
    "\n",
    "reps = []\n",
    "globs = list(pathlib.Path(f_base).glob(f_glob))\n",
    "for glob in tqdm(globs):\n",
    "    model = ue.Compressor.load(str(glob.parents[0]), glob.name, torch.device('cpu'))\n",
    "    rep = agg_cluster_distances(model, cutoff=1000, **options)\n",
    "    reps.append(rep)\n",
    "    tsne_scatter(model, glob, **options)\n",
    "\n",
    "summary = '\\n'.join(reps)    \n",
    "\n",
    "if options['display']:\n",
    "    print(summary)\n",
    "    \n",
    "if options['save']:\n",
    "    fname = (pathlib.Path(f_base) / f_glob).parents[2] / (embedding + '.clusters.txt')\n",
    "    with fname.open(mode='w') as fd:\n",
    "        fd.write(summary)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print bar plot with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_embedding(endpoint: str, fname: str):\n",
    "    import ember.client as ec\n",
    "    \n",
    "    chunk_size = 8192\n",
    "    client = ec.EmberClient(endpoint, chunk_size)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as fd:\n",
    "        vocab = client.get_vocab()\n",
    "        \n",
    "        ds = fd.create_dataset('embedding', shape=(len(vocab), 300))\n",
    "        for i, chunk in tqdm(enumerate(client.gen_chunks()), total=len(vocab)//chunk_size+1):\n",
    "            lower = i * chunk_size\n",
    "            upper = min(ds.shape[0], lower + chunk_size)\n",
    "            ds[lower:upper] = chunk\n",
    "    \n",
    "        client.close()\n",
    "        return ds[:]\n",
    "\n",
    "    \n",
    "def get_embedding(endpoint: str, folder: str, h5file: str):\n",
    "    fname = str(pathlib.Path(folder) / h5file)\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(fname, 'r') as fd:\n",
    "            data = fd['embedding'][:]\n",
    "    except OSError:\n",
    "        data = _create_embedding(endpoint, fname)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_norms(model_args, emb_args, display: bool = True, save: bool = False):\n",
    "    folder = pathlib.Path(model_args[0])\n",
    "    \n",
    "    # embeddings\n",
    "    emb_data = get_embedding(*emb_args)\n",
    "    emb_norms = np.linalg.norm(emb_data, axis=1)\n",
    "    \n",
    "    # clusters\n",
    "    compressor = ue.Compressor.load(*model_args, torch.device('cpu'))\n",
    "    vec_dists, cluster_dists = cluster_distances(compressor)\n",
    "    \n",
    "    # codebooks\n",
    "    codebook_data = compressor.decoder.components.view(-1, 300).detach()\n",
    "    codebook_norms = np.linalg.norm(codebook_data, axis=1)\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_title('Distances and Vector Norms ({})'.format(\n",
    "        folder.parents[0].parts[-1].replace('-', '/')))\n",
    "\n",
    "    labels = [\n",
    "        'embedding\\nnorm',\n",
    "        'codebook\\nnorm',\n",
    "        'cluster\\ndistance',\n",
    "        'cluster radius', ]\n",
    "    \n",
    "    heights = [\n",
    "        emb_norms.mean(),\n",
    "        codebook_norms.mean(),\n",
    "        cluster_dists.mean(),\n",
    "        vec_dists.mean(), ]\n",
    "    \n",
    "    yerrs = [\n",
    "        emb_norms.std()/2,\n",
    "        codebook_norms.std()/2,\n",
    "        cluster_dists.std()/2,\n",
    "        vec_dists.std()/2, ]\n",
    "    \n",
    "    color='blue'\n",
    "    ax.bar(\n",
    "        range(len(heights)), heights, yerr=yerrs, tick_label=labels,\n",
    "        color=CLR[color][1], edgecolor=CLR[color][3], ecolor=CLR[color][3],\n",
    "        linewidth=1, )\n",
    "    \n",
    "    if save:\n",
    "        stem = model_args[1].split('-')[1].split('.')[0]\n",
    "        fname = str(folder.parents[0] / 'images' / ('norms_' + stem))\n",
    "        fig.savefig(fname + '.png')\n",
    "        fig.savefig(fname + '.svg')\n",
    "    \n",
    "    if display:\n",
    "        plt.show(fig)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "# emb_args = 'tcp://localhost:8124', '../opt/embeddings/fasttext', 'wiki.en.400k.h5'\n",
    "# emb_args = 'tcp://localhost:8125', '../opt/embeddings/fasttext', 'wiki.de.400k.h5'\n",
    "emb_args = 'tcp://localhost:8126', '../opt/embeddings/glove', 'glove.6B.300d.h5'\n",
    "\n",
    "experiment = 'tau'\n",
    "embedding = 'glove'\n",
    "\n",
    "path = pathlib.Path('../opt/experiments/' + experiment)\n",
    "globs = list(path.glob(embedding + '-*/compressor/*torch'))\n",
    "\n",
    "for glob in tqdm(globs):\n",
    "    model_args = str(glob.parents[0]), glob.name\n",
    "    plot_norms(model_args, emb_args, display=False, save=True)\n",
    "    \n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ungol-models",
   "language": "python",
   "name": "ungol-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
