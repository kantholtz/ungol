{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Training embcompr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "CLR = {\n",
    "    'blue': ['#e0f3ff', '#aadeff', '#2bb1ff', '#15587f', '#0b2c40'],\n",
    "    'gold': ['#fff3dc', '#ffebc7', '#ffddab', '#b59d79', '#5C4938'],\n",
    "    'red':  ['#ffd8e8', '#ff9db6', '#ff3e72', '#6B404C', '#521424'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as ppt\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def _rolling_mean(a: np.array, window: int):\n",
    "    assert len(a.shape) == 1\n",
    "\n",
    "    a_prev = np.repeat(a[0], window // 2)\n",
    "    a_post = np.repeat(a[-1], window // 2 - 1)\n",
    "\n",
    "    x = np.concatenate((a_prev, a, a_post))\n",
    "    v = np.ones((window, )) / window\n",
    "\n",
    "    return np.convolve(x, v, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_loss(path: pathlib.Path, skip: int):\n",
    "    try:\n",
    "        with h5py.File(str(path), mode='r') as fd:\n",
    "\n",
    "            train_shape, valid_shape = fd['train'].shape, fd['valid'].shape\n",
    "            _, batches = fd['train'].shape\n",
    "            epochs = len(np.where(fd['train'][:].sum(axis=1) > 0)[0])  # early stopping (TODO: may be solved more elegantly)\n",
    "\n",
    "            epochs -= skip\n",
    "            data_train = fd['train'][skip:epochs]\n",
    "            data_valid = fd['valid'][skip:epochs]\n",
    "\n",
    "            if not len(data_train) or not len(data_valid):\n",
    "                print('skipping {} - no data available'.format(str(path)))\n",
    "                return\n",
    "\n",
    "    except OSError as e:\n",
    "        # print(str(e))\n",
    "        print('skipping {} - currently in use'.format(str(path)))\n",
    "        return\n",
    "\n",
    "    return data_train, data_valid, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(selection: str, display: bool, save: bool, skip: int = 20):\n",
    "\n",
    "    def argmin(x: np.array, data: np.array):\n",
    "        y_mean = data.mean(axis=1)\n",
    "        idx_min = y_mean.argmin()\n",
    "        return x[idx_min], y_mean[idx_min]\n",
    "\n",
    "    rows = []\n",
    "    for glob in pathlib.Path('..').glob(selection + '/losses.h5'):\n",
    "\n",
    "        data = load_loss(glob, skip)\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        data_train, data_valid, epochs = data\n",
    "        x = np.arange(skip, epochs + skip)\n",
    "        exp = glob.parts[-2]\n",
    "\n",
    "        row = (exp, )\n",
    "\n",
    "        # add loss minima to data\n",
    "        row = row + argmin(x, data_train)\n",
    "        row = row + argmin(x, data_valid)\n",
    "\n",
    "        best_epoch = row[-2]\n",
    "\n",
    "        # find code entropy\n",
    "        try:\n",
    "            codes_fd = h5py.File(str(glob.parents[0] / 'codes.h5'))\n",
    "            epochs = [int(key) for key in codes_fd['valid'].keys()]\n",
    "            s = epochs[np.argmin([abs(best_epoch - e) for e in epochs])]\n",
    "            row = row + (s, codes_fd['valid'][str(s)]['entropy'].attrs['mean'])\n",
    "\n",
    "        except OSError as e:\n",
    "            print('{} no codes.h5 found'.format(str(glob.parent.name)))\n",
    "            row = row + ('-', '-')\n",
    "\n",
    "        except KeyError:\n",
    "            print('{} no \"valid\" dataset found in codes.h5'.format(str(glob)))\n",
    "            row = row + ('-', '-')\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    headers = ['exp', 't epoch', 't loss', 'v epoch', 'v loss', 'entropy epoch', 'entropy']\n",
    "    rows.sort(key=lambda t: t[4])\n",
    "\n",
    "    assert len(rows), 'no data found'\n",
    "    \n",
    "    if display:\n",
    "        print()\n",
    "        print(tabulate(rows, headers=headers))\n",
    "        print()\n",
    "\n",
    "    if save:\n",
    "        path = glob.parents[1] / 'summary.txt'\n",
    "        print('writing', str(path))\n",
    "        with path.open('w') as fd:\n",
    "            fd.write(tabulate(rows, headers=headers, tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def _loss_line_plot(ax, x, data: np.array, window: int, label_fmt: str,\n",
    "                    color: str = None, show_bounds: bool = True,\n",
    "                    marker = 2, baseline: float = None):\n",
    "\n",
    "    y_min = _rolling_mean(data.min(axis=1), window)\n",
    "    y_max = _rolling_mean(data.max(axis=1), window)\n",
    "\n",
    "    if show_bounds:\n",
    "        ax.plot(x, y_min, color=CLR[color][3], alpha=0.5, lw=0.6)\n",
    "        ax.plot(x, y_max, color=CLR[color][3], alpha=0.5, lw=0.6)\n",
    "        ax.fill_between(x, y_min, y_max, color=CLR[color][0], alpha=0.2)\n",
    "\n",
    "    y_mean = data.mean(axis=1)\n",
    "    ax.plot(x, y_mean, color=CLR[color][2])\n",
    "\n",
    "    # marker and lines\n",
    "\n",
    "    line_style = dict(linestyle='dashed', lw=1, alpha=0.5, color=CLR[color][3])\n",
    "\n",
    "    patches = []\n",
    "    if baseline is not None:\n",
    "        ax.axhline(baseline, 0, 1, **line_style)\n",
    "        patches.append(ppt.Patch(\n",
    "            color='black', label='Baseline: {}'.format(baseline)))\n",
    "\n",
    "    if show_bounds:\n",
    "        ax.vlines(x[0], y_min[0] - 1, y_max[0] + 1, **line_style)\n",
    "        ax.vlines(x[-1], y_min[-1] - 1, y_max[-1] + 1, **line_style)\n",
    "\n",
    "    idx_min = y_mean.argmin()\n",
    "    ax.scatter(x[idx_min], y_mean[idx_min], marker=marker, s=100, color=CLR[color][2])\n",
    "\n",
    "    # legend\n",
    "\n",
    "    patches.insert(0, ppt.Patch(\n",
    "        color=CLR[color][2],\n",
    "        label=label_fmt.format(y_mean[idx_min], x[idx_min])))\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "def plot_loss(path: pathlib.Path, display: bool, save: bool, skip: int = 0, window: int = 50, baseline: float = None):\n",
    "\n",
    "    name_exp = '/'.join(path.parts[-3:-1])\n",
    "    out_dir = path.parents[0]/'images'\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # data aggregation\n",
    "    data = load_loss(path, skip)\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    data_train, data_valid, epochs = data\n",
    "\n",
    "    if epochs < 50:\n",
    "        print('not enough data:', epochs)\n",
    "        return\n",
    "\n",
    "    data_train = data_train[:epochs]\n",
    "    data_valid = data_valid[:epochs]\n",
    "    x = np.arange(skip, epochs + skip)\n",
    "\n",
    "    # clip above baseline\n",
    "    data_train[data_train > baseline] = baseline\n",
    "    data_valid[data_valid > baseline] = baseline\n",
    "\n",
    "    def fig_before(title: str):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Distance Loss')\n",
    "        return fig, ax\n",
    "\n",
    "    def fig_after(fix, ax, patches, fname):\n",
    "        ax.legend(handles=patches)\n",
    "        if display:\n",
    "            plt.show(fig)\n",
    "        if save:\n",
    "            for out_file in [str(out_dir/fname) + s for s in ('.png', '.svg')]:\n",
    "                # print('saving to', out_file)\n",
    "                fig.savefig(out_file)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    # plot three plots\n",
    "\n",
    "#     fig, ax = fig_before('Training Loss ({})'.format(name_exp))\n",
    "#     patch = _loss_line_plot(\n",
    "#         ax, x, data_train, window, 'Min. Training: {:2.3f} (Epoch {})', color='blue', baseline=baseline)\n",
    "#     fig_after(fig, ax, patch, 'loss-training')\n",
    "\n",
    "#     fig, ax = fig_before('Validation Loss ({})'.format(name_exp))\n",
    "#     patch = _loss_line_plot(\n",
    "#         ax, x, data_valid, window, 'Min. Validation: {:2.3f} (Epoch {})', color='red', baseline=baseline)\n",
    "#     fig_after(fig, ax, patch, 'loss-validation')\n",
    "\n",
    "    fig, ax = fig_before('Loss ({})'.format(name_exp))\n",
    "    patch1 = _loss_line_plot(\n",
    "        ax, x, data_train, window,\n",
    "        'Min. Training: {:2.3f} (Epoch {})', color='blue',\n",
    "        show_bounds=False, marker=3)\n",
    "    patch2 = _loss_line_plot(\n",
    "        ax, x, data_valid, window,\n",
    "        'Min. Validation: {:2.3f} (Epoch {})', color='red',\n",
    "        show_bounds=False, baseline=baseline)\n",
    "    fig_after(fig, ax, patch1 + patch2, 'loss')\n",
    "\n",
    "def plot_losses(selection, display: bool = True, save: bool = True, baseline: float = None):\n",
    "    for glob in pathlib.Path('..').glob(selection + 'losses.h5'):\n",
    "        print('plot loss', str(glob))\n",
    "        plot_loss(glob, display, save, baseline=baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Encoder Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_activation_train(codefile: pathlib.Path, display: bool, save: bool):\n",
    "\n",
    "    path = codefile.parents[0]\n",
    "    fd = h5py.File(str(codefile), mode='r')\n",
    "    name_exp = '/'.join(path.parts[-2:])\n",
    "\n",
    "    try:\n",
    "        group = fd['train']\n",
    "    except KeyError:\n",
    "        print('no \"train\" datagroup: only \"{}\"'.format(str(list(fd.keys()))))\n",
    "        return\n",
    "\n",
    "    out_dir = path / 'images'\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def fig_before(title: str):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(title)\n",
    "        return fig, ax\n",
    "\n",
    "    def fig_after(fig, ax, fname):\n",
    "        if display:\n",
    "            plt.show(fig)\n",
    "        if save:\n",
    "            for out_file in [str(out_dir/fname) + s for s in ('.png', '.svg')]:\n",
    "                # print('saving to', out_file)\n",
    "                fig.savefig(out_file)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    for epoch in tqdm(sorted([int(key) for key in group.keys()])):\n",
    "        hist = group[str(epoch)]['histogram']\n",
    "\n",
    "        bin_edges = hist.attrs['bin_edges']\n",
    "        x = [(a + b) / 2 for a, b in zip(bin_edges, bin_edges[1:])]\n",
    "        y = hist[:]\n",
    "\n",
    "        # pie plot\n",
    "\n",
    "        fig, ax = fig_before('Encoder Activations (Epoch {}) \\n ({})\\n'.format(\n",
    "            epoch, name_exp))\n",
    "\n",
    "        l0 = 'x < {:2.2f}'.format(bin_edges[2])\n",
    "        l1 = 'other'.format(bin_edges[1], bin_edges[-3])\n",
    "        l2 = '{:2.2f} < x'.format(bin_edges[-2])\n",
    "        sizes = y[0], sum(y[1:-1]), y[-1]\n",
    "\n",
    "        colors = CLR['blue'], CLR['red'], CLR['gold']\n",
    "\n",
    "        wp_outer = dict(wedgeprops=dict(width=0.3, edgecolor='w'))\n",
    "        wp_inner = dict(wedgeprops=dict(width=0.1, edgecolor='w'))\n",
    "\n",
    "        pct_style = dict(pctdistance=0.4, autopct='%1.1f%%')\n",
    "\n",
    "        kw_outer = {**wp_outer, **pct_style, 'colors': [c[2] for c in colors]}\n",
    "        kw_inner = {**wp_inner, 'colors': [c[0] for c in colors]}\n",
    "\n",
    "        ax.pie(sizes, labels=(l0, l1, l2), startangle=0, **kw_outer)\n",
    "        ax.pie(sizes, radius=0.7, startangle=0, **kw_inner)\n",
    "\n",
    "        # circle = plt.Circle((0,0), 0.8, color='w', fc=CLR['blue'][0], lw=1)\n",
    "        # ax.add_artist(circle)\n",
    "        plt.axis('equal')\n",
    "\n",
    "        fig_after(fig, ax, 'encoder-activation-train_{}'.format(epoch))\n",
    "\n",
    "\n",
    "def plot_activations_train(selection, display: bool = True, save: bool = True):\n",
    "    for glob in pathlib.Path('..').glob(selection + 'codes.h5'):\n",
    "        print('training activations', str(glob))\n",
    "        plot_activation_train(glob, display, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def _plot_activation_bar(fig, ax, arr):\n",
    "\n",
    "    def color_gen(switch: int = 1, kind: int = 2):\n",
    "        on = False\n",
    "        count = 1\n",
    "        while True:\n",
    "            if on:\n",
    "                yield CLR['blue'][kind]\n",
    "            else:\n",
    "                yield CLR['red'][kind]\n",
    "\n",
    "            if count % switch == 0:\n",
    "                on = not on\n",
    "            count += 1\n",
    "\n",
    "    def color_map(amount: int, switch: int):\n",
    "        gen = color_gen(switch=switch)\n",
    "        return [next(gen) for _ in range(amount)]\n",
    "\n",
    "    M, K = arr.shape\n",
    "    fig.set_size_inches(40, 10)\n",
    "\n",
    "    # draw codebook separators\n",
    "    line_style = dict(color='black', ls='dashed', lw=1)\n",
    "    for i, bg_color in zip(range(M), color_gen(kind=0)):\n",
    "        ax.axvline(x=i * (K + 1) - 1, **line_style)\n",
    "        begin = i * (K + 1) - 1\n",
    "        end = begin + K + 1\n",
    "        ax.axvspan(begin, end, color=bg_color, alpha=0.2)\n",
    "\n",
    "    ax.axvline(x=M * (K + 1) - 1, **line_style)\n",
    "\n",
    "    # arr shape: (n, M, K)\n",
    "    # retrieve selection per codebook (along dim=1)\n",
    "    # adding [0] as seperator element between codebooks\n",
    "    sums = np.array([np.concatenate((arr[i], [0])) for i in range(M)])\n",
    "    ax.bar(range(len(sums.flat)), sums.flat, color=color_map(M * (K + 1), K + 1), align='edge')\n",
    "\n",
    "\n",
    "def plot_activation_valid(codefile: pathlib.Path, display: bool, save: bool):\n",
    "\n",
    "    path = codefile.parents[0]\n",
    "\n",
    "    try:\n",
    "        fd = h5py.File(str(codefile), mode='r')\n",
    "        group = fd['valid']\n",
    "    except OSError:\n",
    "        print('skipping {}, currently in use'.format(str(path)))\n",
    "        return\n",
    "    except KeyError:\n",
    "        print('no \"train\" datagroup: only \"{}\"'.format(str(list(fd.keys()))))\n",
    "        return\n",
    "\n",
    "    out_dir = path / 'images'\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def fig_before(title: str):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(title)\n",
    "        return fig, ax\n",
    "\n",
    "    def fig_after(fig, ax, fname):\n",
    "        if display:\n",
    "            plt.show(fig)\n",
    "        if save:\n",
    "            for out_file in [str(out_dir/fname) + s for s in ('.png', '.svg')]:\n",
    "                # print('saving to', out_file)\n",
    "                fig.savefig(out_file)\n",
    "\n",
    "        fig.clear()\n",
    "        plt.close(fig)\n",
    "\n",
    "    # stupid thing to mitigate the memory leak...\n",
    "    # process manually chunk-wise if end < len(epochs)\n",
    "    epochs = sorted([int(key) for key in group.keys()])\n",
    "    start, end = 0, 500\n",
    "    if end - start < len(epochs):\n",
    "        print('WARNING: only using data subset!')\n",
    "        print('current epoch range: ', start, end)\n",
    "\n",
    "    epochs = epochs[start:end]\n",
    "    for i, epoch in tqdm(enumerate(epochs), total=len(epochs)):\n",
    "        counts = group[str(epoch)]['counts'][:]\n",
    "\n",
    "        fig, ax = fig_before('Encoder Activations (Epoch {})'.format(epoch))\n",
    "        _plot_activation_bar(fig, ax, counts)\n",
    "        fig_after(fig, ax, 'encoder-activation-valid_{}'.format(epoch))\n",
    "\n",
    "        if i == end:\n",
    "            break\n",
    "\n",
    "\n",
    "def plot_activations_valid(selection, display: bool = True, save: bool = True):\n",
    "    for glob in pathlib.Path('..').glob(selection + 'codes.h5'):\n",
    "        print('code bars', str(glob))\n",
    "        plot_activation_valid(glob, display, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Play the organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# note: there is a small memory leak becoming obvious when plotting many figures.\n",
    "# I have no idea why that is, but it seems to come from pyplot.\n",
    "# It does not help, that it also only occurs sometimes and not consistently...\n",
    "\n",
    "experiment = 'experiments/enwiki'\n",
    "\n",
    "# --- RAW\n",
    "\n",
    "# embedding = 'glove', 20.17\n",
    "# embedding = 'fasttext.en', 12.11\n",
    "# embedding = 'fasttext.de', 11.47\n",
    "\n",
    "# --- BOV\n",
    "\n",
    "embedding = '**', 2\n",
    "\n",
    "options = dict(display=True, save=True)\n",
    "\n",
    "selection = f'opt/{experiment}/{embedding[0]}/'\n",
    "\n",
    "summarize(selection, **options)\n",
    "plot_losses(selection, baseline=embedding[1], **options)\n",
    "# plot_activations_train(selection, **options)\n",
    "# plot_activations_valid(selection, **options)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "training.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
