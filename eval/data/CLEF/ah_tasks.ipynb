{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import attr\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import and Initialization\n",
    " \n",
    "Yep, three documents - three encodings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('examples/E0008/samples/19940103', mode='r', encoding='iso-8859-1') as f:\n",
    "    docs_raw = f.read()\n",
    "    \n",
    "with open('truth/CLEF2003_ah-mono-de.txt', mode='r', encoding='ascii') as f:\n",
    "    truth_raw = [line for line in f.readlines() if len(line.strip()) > 0]\n",
    "    \n",
    "with open('truth/CLEF2003_ah-mono-de_topics.xml', mode='r', encoding='utf-8') as f:\n",
    "    topics_raw = f.read()\n",
    "\"\"\"    \n",
    "\n",
    "@attr.s\n",
    "class Doc():\n",
    "    doc_id:      str = attr.ib()\n",
    "    text:        str = attr.ib()\n",
    "    title: List[str] = attr.ib(default=attr.Factory(list))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '{} - {}\\n{}...'.format(self.doc_id, self.title, self.text[:300])\n",
    "        \n",
    "@attr.s\n",
    "class Topic():\n",
    "    top_id:      str = attr.ib()\n",
    "    title:       str = attr.ib()\n",
    "    description: str = attr.ib()\n",
    "    narrative:   str = attr.ib()\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"[{}] {}\\n{}\\n\".format(self.top_id, self.title, self.description)\n",
    "    \n",
    "@attr.s\n",
    "class Truth():\n",
    "    file:    str = attr.ib()\n",
    "    raw:     str = attr.ib()\n",
    "        \n",
    "@attr.s\n",
    "class Dataset():\n",
    "    year:                         str = attr.ib()\n",
    "    truth: Dict[str, Dict[str, bool]] = attr.ib(default=attr.Factory(dict))\n",
    "    docs:              Dict[str, Doc] = attr.ib(default=attr.Factory(dict))\n",
    "    topics:          Dict[str, Topic] = attr.ib(default=attr.Factory(dict))\n",
    "        \n",
    "    # based on the examples, only some topics are actually relevant\n",
    "    # because only they have related documents - this is a set of topic ids\n",
    "    relevant: Set[str] = attr.ib(default=attr.Factory(set))\n",
    "        \n",
    "datasets = []\n",
    "for year in '2000', '2001', '2002', '2003':\n",
    "    datasets.append(Dataset(year=year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading examples/E0008/samples/19940103 yielded 0 duplicates (0 current, 125 new)\n",
      "reading examples/E0038/samples/19951211 yielded 0 duplicates (125 current, 136 new)\n",
      "reading examples/E0036/samples/19940228_Sample yielded 0 duplicates (261 current, 26 new)\n",
      "reading examples/E0038/samples/19940627 yielded 0 duplicates (287 current, 138 new)\n",
      "\n",
      "total documents: 425\n",
      "only SPIEGEL: True\n",
      "\n",
      " SPIEGEL9495-000007 - ['Heuchlerisches Vertuschen']\n",
      "Man rät schwulen Pastoren, ihre Beziehungen zu verheimlichen, nicht aber diese abzubrechen. Es geht also nicht um scheinbar \"christliche\" Werte, sondern nur um die Aufrechterhaltung des Scheins. Dieses heuchlerische Vertuschen und Mißachten der Realität macht die Kirche unglaubwürdig und entfernt si...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def soup2doc(doc_node) -> Doc:\n",
    "    text = ' '.join(doc_node.find('text').string.strip().split())\n",
    "    doc_id = doc_node.find('docid').string.strip()\n",
    "    doc = Doc(text=text, doc_id=doc_id)\n",
    "    for title in doc_node.find_all('title'):\n",
    "        doc.title.append(title.string.strip())\n",
    "    return doc\n",
    "\n",
    "\n",
    "def read_docs(soup) -> Dict[str, Doc]:\n",
    "    docs = {}\n",
    "    for doc_node in soup:\n",
    "        if len(doc_node) <= 1 or doc_node.find('text') is None:\n",
    "            continue\n",
    "    \n",
    "        doc = soup2doc(doc_node)\n",
    "        docs[doc.doc_id] = doc\n",
    "    \n",
    "    return docs\n",
    "\n",
    "\n",
    "doc_files = (\n",
    "    'E0008/samples/19940103',\n",
    "    'E0038/samples/19951211',\n",
    "    'E0036/samples/19940228_Sample',\n",
    "    'E0038/samples/19940627',\n",
    ")\n",
    "\n",
    "print()\n",
    "docs = {}\n",
    "for file in doc_files:\n",
    "    fname = 'examples/{}'.format(file)\n",
    "    with open(fname, mode='r', encoding='iso-8859-1') as f:\n",
    "        \n",
    "        soup = bs(f.read(), 'html.parser')\n",
    "        new = read_docs(soup)\n",
    "        \n",
    "        print('reading {} yielded {} duplicates ({} current, {} new)'.format(\n",
    "            fname, len(docs.keys() & new.keys()), len(docs), len(new)))\n",
    "        \n",
    "        docs = {**docs, **new}\n",
    "        \n",
    "print('\\ntotal documents:', len(docs))\n",
    "print('only SPIEGEL:', all([s.startswith('SPIEGEL') for s in docs]))\n",
    "\n",
    "print('\\n', docs['SPIEGEL9495-000007'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.docs = docs\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "looking at year 2000\n",
      "  imported 37 topics\n",
      "\n",
      "looking at year 2001\n",
      "  imported 49 topics\n",
      "\n",
      "looking at year 2002\n",
      "  imported 50 topics\n",
      "\n",
      "looking at year 2003\n",
      "  imported 56 topics\n",
      "\n",
      "example:\n",
      "[150-AH] AI gegen Todesstrafe\n",
      "Finde Berichte über direkte Aktionen von Amnesty International gegen die Todesstrafe.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def soup2topic(topic_node):\n",
    "    args = 'identifier', 'title', 'description', 'narrative'\n",
    "    return Topic(*[topic_node.find(s).string for s in args])\n",
    "\n",
    "fmt_path = 'truth/CLEF{}_ah-mono-de_topics.xml'\n",
    "for dataset in datasets:\n",
    "    print('\\nlooking at year {}'.format(dataset.year))\n",
    "    \n",
    "    with open(fmt_path.format(dataset.year), mode='r', encoding='utf-8') as f:\n",
    "        raw = f.read()\n",
    "    \n",
    "    soup = bs(raw, 'xml')\n",
    "    for topic_node in soup.find_all('topic'):\n",
    "        topic = soup2topic(topic_node)\n",
    "        dataset.topics[topic.top_id] = topic\n",
    "        \n",
    "    print('  imported {} topics'.format(len(dataset.topics)))\n",
    "\n",
    "print('\\nexample:')\n",
    "print(datasets[-1].topics['150-AH'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "looking at year 2000\n",
      "  read 11335 ground truth samples\n",
      "  imported 37 ground truth topics\n",
      "  of those, only 30 are relevant\n",
      "\n",
      "looking at year 2001\n",
      "  read 16726 ground truth samples\n",
      "  imported 49 ground truth topics\n",
      "  of those, only 33 are relevant\n",
      "\n",
      "looking at year 2002\n",
      "  read 19394 ground truth samples\n",
      "  imported 50 ground truth topics\n",
      "  of those, only 32 are relevant\n",
      "\n",
      "looking at year 2003\n",
      "  read 21534 ground truth samples\n",
      "  imported 56 ground truth topics\n",
      "  of those, only 29 are relevant\n",
      "\n",
      "subsets?\n",
      "  2000 subset of 2001? False\n",
      "  2001 subset of 2002? False\n",
      "  2002 subset of 2003? False\n"
     ]
    }
   ],
   "source": [
    "def read_truth(raw, dataset):\n",
    "    truth = defaultdict(dict)\n",
    "    sample_count = len(raw)\n",
    "    \n",
    "    for line in raw:\n",
    "        top_id, _, doc_id, val = line.split()\n",
    "        \n",
    "        assert val == '1' or val == '0'\n",
    "        assert top_id in dataset.topics\n",
    "        \n",
    "        truth[top_id][doc_id] = True if val == '1' else False\n",
    "    \n",
    "        if doc_id in dataset.docs:\n",
    "            dataset.relevant.add(top_id)\n",
    "\n",
    "    assert sample_count == sum([len(v) for v in truth.values()])\n",
    "    return truth\n",
    "\n",
    "\n",
    "fmt_path = 'truth/CLEF{}_ah-mono-de.txt'\n",
    "for dataset in datasets:\n",
    "    print('\\nlooking at year {}'.format(dataset.year))\n",
    "    with open(fmt_path.format(dataset.year), mode='r', encoding='ascii') as f:\n",
    "        raw = [line for line in f.readlines() if len(line.strip()) > 0]\n",
    "\n",
    "    print('  read {} ground truth samples'.format(len(raw)))\n",
    "    dataset.truth = read_truth(raw, dataset)\n",
    "    print('  imported {} ground truth topics'.format(len(dataset.truth)))\n",
    "    print('  of those, only {} are relevant'.format(len(dataset.relevant)))\n",
    "    \n",
    "print('\\nsubsets?')\n",
    "for d1, d2 in zip(datasets, datasets[1:]):\n",
    "    assert d1 <= d2\n",
    "    subset = all([k in d2.truth for k in d1.truth])\n",
    "    print('  {} subset of {}? {}'.format(d1.year, d2.year, subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze relevant ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "looking at year 2000\n",
      "  topic:   25-AH -   4 true, 3/287 in corpus\n",
      "  topic:   16-AH -   5 true, 2/307 in corpus\n",
      "  topic:   39-AH -  16 true, 1/314 in corpus\n",
      "  topic:   35-AH -   1 true, 1/343 in corpus\n",
      "  topic:   27-AH -  46 true, 1/315 in corpus\n",
      "  topic:   24-AH -   2 true, 1/167 in corpus\n",
      "  topic:   12-AH -  23 true, 2/256 in corpus\n",
      "  topic:   38-AH -   8 true, 3/348 in corpus\n",
      "  topic:   10-AH -  21 true, 5/355 in corpus\n",
      "  topic:    5-AH - 101 true, 2/306 in corpus\n",
      "  topic:   29-AH -   4 true, 3/275 in corpus\n",
      "  topic:   13-AH -  48 true, 3/199 in corpus\n",
      "  topic:    8-AH -   4 true, 7/302 in corpus\n",
      "  topic:   37-AH -  56 true, 1/165 in corpus\n",
      "  topic:    9-AH -   2 true, 2/393 in corpus\n",
      "  topic:   26-AH -  48 true, 1/421 in corpus\n",
      "  topic:   33-AH -  21 true, 2/238 in corpus\n",
      "  topic:   15-AH -  14 true, 5/304 in corpus\n",
      "  topic:   20-AH -  29 true, 5/309 in corpus\n",
      "  topic:    4-AH -  13 true, 1/353 in corpus\n",
      "  topic:   18-AH -  12 true, 2/421 in corpus\n",
      "  topic:   11-AH -   4 true, 2/308 in corpus\n",
      "  topic:    7-AH -  74 true, 1/298 in corpus\n",
      "  topic:   34-AH -  37 true, 1/282 in corpus\n",
      "  topic:   21-AH -   5 true, 2/284 in corpus\n",
      "  topic:    3-AH -  19 true, 2/211 in corpus\n",
      "  topic:   32-AH -  36 true, 3/232 in corpus\n",
      "  topic:    6-AH -   1 true, 2/310 in corpus\n",
      "  topic:   31-AH -  32 true, 4/282 in corpus\n",
      "  topic:   40-AH -  26 true, 1/278 in corpus\n",
      "\n",
      "looking at year 2001\n",
      "  topic:   52-AH -   7 true, 2/343 in corpus\n",
      "  topic:   76-AH -  55 true, 1/256 in corpus\n",
      "  topic:   83-AH -   9 true, 1/302 in corpus\n",
      "  topic:   48-AH -  55 true, 1/440 in corpus\n",
      "  topic:   71-AH -  13 true, 1/379 in corpus\n",
      "  topic:   43-AH -   2 true, 1/529 in corpus\n",
      "  topic:   78-AH -   8 true, 1/278 in corpus\n",
      "  topic:   73-AH -  24 true, 1/265 in corpus\n",
      "  topic:   57-AH -  11 true, 2/289 in corpus\n",
      "  topic:   49-AH -  18 true, 3/347 in corpus\n",
      "  topic:   45-AH - 106 true, 1/224 in corpus\n",
      "  topic:   79-AH -  12 true, 1/302 in corpus\n",
      "  topic:   75-AH -  16 true, 4/417 in corpus\n",
      "  topic:   82-AH -  27 true, 2/372 in corpus\n",
      "  topic:   77-AH -  13 true, 3/355 in corpus\n",
      "  topic:   85-AH -  74 true, 3/422 in corpus\n",
      "  topic:   53-AH -  32 true, 2/469 in corpus\n",
      "  topic:   41-AH -  28 true, 2/254 in corpus\n",
      "  topic:   69-AH -   7 true, 4/377 in corpus\n",
      "  topic:   54-AH -   3 true, 1/549 in corpus\n",
      "  topic:   56-AH -  36 true, 2/365 in corpus\n",
      "  topic:   59-AH -   6 true, 4/382 in corpus\n",
      "  topic:   66-AH -  51 true, 2/227 in corpus\n",
      "  topic:   70-AH -  20 true, 4/210 in corpus\n",
      "  topic:   84-AH -   5 true, 2/577 in corpus\n",
      "  topic:   60-AH -  57 true, 1/415 in corpus\n",
      "  topic:   72-AH -  20 true, 3/287 in corpus\n",
      "  topic:   80-AH - 120 true, 2/246 in corpus\n",
      "  topic:   65-AH -  65 true, 1/525 in corpus\n",
      "  topic:   46-AH -  10 true, 1/239 in corpus\n",
      "  topic:   51-AH -   6 true, 2/390 in corpus\n",
      "  topic:   64-AH -   1 true, 2/586 in corpus\n",
      "  topic:   61-AH -  43 true, 1/280 in corpus\n",
      "\n",
      "looking at year 2002\n",
      "  topic:  101-AH -  38 true, 1/338 in corpus\n",
      "  topic:  130-AH -  15 true, 2/312 in corpus\n",
      "  topic:  135-AH -  87 true, 1/381 in corpus\n",
      "  topic:  125-AH -  70 true, 3/383 in corpus\n",
      "  topic:  114-AH -  28 true, 2/296 in corpus\n",
      "  topic:  118-AH -   9 true, 1/385 in corpus\n",
      "  topic:  120-AH -   6 true, 2/315 in corpus\n",
      "  topic:  138-AH -  31 true, 1/357 in corpus\n",
      "  topic:  109-AH -   7 true, 3/516 in corpus\n",
      "  topic:  106-AH -  57 true, 3/459 in corpus\n",
      "  topic:  140-AH -  81 true, 1/572 in corpus\n",
      "  topic:  124-AH -  82 true, 4/462 in corpus\n",
      "  topic:   98-AH -  25 true, 4/451 in corpus\n",
      "  topic:  128-AH -  13 true, 3/571 in corpus\n",
      "  topic:   94-AH -  32 true, 2/352 in corpus\n",
      "  topic:  133-AH - 110 true, 3/456 in corpus\n",
      "  topic:  131-AH -  66 true, 7/612 in corpus\n",
      "  topic:  111-AH -   8 true, 4/496 in corpus\n",
      "  topic:  117-AH -  45 true, 1/457 in corpus\n",
      "  topic:  107-AH -  42 true, 1/383 in corpus\n",
      "  topic:  137-AH -   1 true, 1/573 in corpus\n",
      "  topic:   97-AH -  15 true, 2/422 in corpus\n",
      "  topic:  129-AH -  45 true, 1/261 in corpus\n",
      "  topic:   93-AH -  36 true, 1/374 in corpus\n",
      "  topic:  105-AH -  55 true, 2/378 in corpus\n",
      "  topic:  103-AH - 119 true, 1/340 in corpus\n",
      "  topic:  122-AH -  19 true, 2/398 in corpus\n",
      "  topic:   96-AH -  27 true, 1/399 in corpus\n",
      "  topic:  113-AH -  25 true, 6/688 in corpus\n",
      "  topic:  116-AH -  31 true, 2/336 in corpus\n",
      "  topic:  126-AH -  23 true, 1/645 in corpus\n",
      "  topic:  139-AH -  28 true, 2/376 in corpus\n",
      "\n",
      "looking at year 2003\n",
      "  topic:  188-AH -  45 true, 3/484 in corpus\n",
      "  topic:  160-AH -   1 true, 2/587 in corpus\n",
      "  topic:  177-AH -   7 true, 5/617 in corpus\n",
      "  topic:  158-AH -   3 true, 1/337 in corpus\n",
      "  topic:  180-AH -  65 true, 2/255 in corpus\n",
      "  topic:  196-AH -   6 true, 3/262 in corpus\n",
      "  topic:  142-AH -  65 true, 2/108 in corpus\n",
      "  topic:  155-AH -  24 true, 1/481 in corpus\n",
      "  topic:  149-AH -  12 true, 2/305 in corpus\n",
      "  topic:  200-AH -  66 true, 3/501 in corpus\n",
      "  topic:  148-AH -  12 true, 1/188 in corpus\n",
      "  topic:  194-AH -   2 true, 3/671 in corpus\n",
      "  topic:  141-AH -   8 true, 1/411 in corpus\n",
      "  topic:  145-AH -  10 true, 1/574 in corpus\n",
      "  topic:  156-AH -  29 true, 4/663 in corpus\n",
      "  topic:  169-AH -  10 true, 3/499 in corpus\n",
      "  topic:  183-AH -   8 true, 3/376 in corpus\n",
      "  topic:  154-AH -  19 true, 1/335 in corpus\n",
      "  topic:  189-AH -   6 true, 1/251 in corpus\n",
      "  topic:  173-AH -  10 true, 2/424 in corpus\n",
      "  topic:  175-AH -  11 true, 3/586 in corpus\n",
      "  topic:  178-AH -  21 true, 2/633 in corpus\n",
      "  topic:  184-AH -  40 true, 2/446 in corpus\n",
      "  topic:  166-AH -   2 true, 1/412 in corpus\n",
      "  topic:  168-AH -  17 true, 1/308 in corpus\n",
      "  topic:  174-AH -  36 true, 3/468 in corpus\n",
      "  topic:  181-AH - 226 true, 2/295 in corpus\n",
      "  topic:  185-AH -   7 true, 1/292 in corpus\n",
      "  topic:  164-AH -  72 true, 1/431 in corpus\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print('\\nlooking at year {}'.format(dataset.year))\n",
    "    for top_id in dataset.relevant:\n",
    "        dic = dataset.truth[top_id]\n",
    "        print('  topic: {:>7} - {:3d} true, {}/{} in corpus'.format(\n",
    "            top_id, \n",
    "            len([v for v in dic if dic[v]]),\n",
    "            len([v for v in dic if v in docs]),\n",
    "            len(dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "looking at year 2000\n",
      "  found 5-AH with relevant examples\n",
      "  found 15-AH with relevant examples\n",
      "  found 32-AH with relevant examples\n",
      "\n",
      "looking at year 2001\n",
      "  found 48-AH with relevant examples\n",
      "  found 85-AH with relevant examples\n",
      "  found 46-AH with relevant examples\n",
      "\n",
      "looking at year 2002\n",
      "  found 125-AH with relevant examples\n",
      "  found 124-AH with relevant examples\n",
      "  found 98-AH with relevant examples\n",
      "  found 94-AH with relevant examples\n",
      "  found 93-AH with relevant examples\n",
      "  found 103-AH with relevant examples\n",
      "\n",
      "looking at year 2003\n",
      "  found 142-AH with relevant examples\n",
      "  found 156-AH with relevant examples\n",
      "  found 174-AH with relevant examples\n",
      "  found 181-AH with relevant examples\n",
      "  found 185-AH with relevant examples\n"
     ]
    }
   ],
   "source": [
    "true_examples = defaultdict(dict)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('\\nlooking at year {}'.format(dataset.year))\n",
    "\n",
    "    for topic_id in dataset.relevant:\n",
    "        samples = dataset.truth[topic_id].items()\n",
    "        relevant_docs = [doc_id for doc_id, val in samples if val and doc_id in docs]\n",
    "        # print('  {:>6} any relevant docs: {}'.format(topic_id, any(relevant_docs)))\n",
    "        \n",
    "        if any(relevant_docs):\n",
    "            print('  found {} with relevant examples'.format(topic_id))\n",
    "            true_examples[dataset.year][topic_id] = relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "looking at year 2000\n",
      "\n",
      "  EXAMPLE 0\n",
      "\n",
      "[5-AH] Mitgliedschaft in der Europäischen Union\n",
      "Die Haltung von Nicht-Mitgliedstaaten zum Beitritt zur Europäischen Gemeinschaft oder Europäischen Union soll ermittelt werden.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-000074 - ['Skandinavien', 'Arktischer Winter']\n",
      "Mit ihren 20 Kühen im Stall zählen Riitta und Pentti Neitola zu den ganz großen Milchbauern im finnischen Lappland. Steiniger Boden, endlose Kiefern- und Birkenwälder, lange dunkle Winter, die sich schon im September mit Frost und Schnee ankündigen und erst im Mai enden - unter solch unwirtlichen Be...\n",
      "\n",
      "  EXAMPLE 1\n",
      "\n",
      "[15-AH] Wettbewerbsfähigkeit der europäischen Industrie\n",
      "Welche Faktoren beeinträchtigen die Wettbewerbsfähigkeit der europäischen Industrie auf den Weltmärkten?\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-000026 - ['Ein Europa für die Zukunft']\n",
      "Der europäische Einigungsprozeß ist ins Stocken geraten, der Vertrag von Maastricht markiert ein Ende, nicht einen Neubeginn. Er hat die Mitglieder der Europäischen Gemeinschaft gespalten, ihre Bürger in Pro- und Anti-Europäer, die Staaten selbst in Schnellzug- und Bummelzug-Unionisten. Das Wort von...\n",
      "\n",
      "  EXAMPLE 2\n",
      "\n",
      "[32-AH] Weibliche Priester\n",
      "Gesucht sind Dokumente über die Ordination von weiblichen Priestern in europäischen Kirchen.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013636 - ['Großbritannien', 'Zulauf für den Papst']\n",
      "Der anglikanischen Staatskirche laufen immer mehr Geistliche weg. Vergangene Woche ließen sich elf Würdenträger in der Londoner Westminster-Kathedrale von Kardinal Hume, Oberhaupt der britischen Katholiken, zu Priestern weihen. Damit sind allein in den vergangenen Monaten fünf anglikanische Bischöfe...\n",
      "\n",
      "looking at year 2001\n",
      "\n",
      "  EXAMPLE 0\n",
      "\n",
      "[48-AH] Friedenstruppen in Bosnien\n",
      "Gründe für den Rückzug der UN-Blauhelmtruppen aus Bosnien.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-001032 - ['Zugleich Täter und Opfer?']\n",
      "In Bosnien geschieht ein Völkermord, daher hätten die radikal-serbischen Aggressoren längst bombardiert werden sollen. Schließlich hat Nazi-Deutschland auch erst Ruhe gegeben, als die Alliierten deutsche Städte niedergebombt haben. *UNTERSCHRIFT: Erlangen MONIKA ROMHANYI Das Nato-Ultimatum mußte nic...\n",
      "\n",
      "  EXAMPLE 1\n",
      "\n",
      "[85-AH] Hilfsprogramm \"Schildkröte\" in Ruanda\n",
      "Suche detaillierte Informationen über das Programm \"Schildkröte\", eine humanitäre Hilfsaktion Frankreichs in Ruanda.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-003350 - ['Ruanda', 'GENDARM IN AFRIKA']\n",
      "Der Ruf \"Die Franzosen kommen\" löste Schrecken aus. \"Sind die verrückt geworden?\" erregte sich im Hotel Amohoro, wo das Uno-Hauptquartier in Kigali untergebracht ist, ein russischer Offizier in Diensten der Weltorganisation. \"Nun werden wir im besten Fall rausgeschmissen und im schlimmsten als Geise...\n",
      "\n",
      "  EXAMPLE 2\n",
      "\n",
      "[46-AH] Embargo gegen den Irak\n",
      "Welche Auswirkungen hat das UN-Embargo auf das Leben der irakischen Bevölkerung gehabt?\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013674 - ['Irak', 'Tödliche Sanktionen']\n",
      "Mehr als 560 000 irakische Kinder sind nach Schätzung von US-Wissenschaftlern an den Folgen des Wirtschaftsboykotts gestorben, der vor fünf Jahren gegen den Wüstenstaat verhängt wurde. Ende August hatten die Gesundheitsexperten im Auftrag der Vereinten Nationen den Irak bereist. Wie die Forscher vor...\n",
      "\n",
      "looking at year 2002\n",
      "\n",
      "  EXAMPLE 0\n",
      "\n",
      "[125-AH] Europäische Einheitswährung\n",
      "Wie sieht der Zeitplan für die Einführung einer europäischen Einheitswährung aus?\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013601 - ['Die Schuldigen: Wir']\n",
      "Aus der International Herald Tribune können wir erfahren, wer die Massenstreiks in Frankreich (Charles de Gaulle: \"chienlit\") verursacht hat: die Deutschen. Sie bestehen auf den Stabilitätskriterien von Maastricht und zwingen so die anderen Länder, Austerity zu üben. Es ist also nicht Jacques Chirac...\n",
      "\n",
      "  EXAMPLE 1\n",
      "\n",
      "[124-AH] Gemeinsame Außen- und Sicherheitspolitik (GASP)\n",
      "Gesucht sind Dokumente zur Etablierung einer gemeinsamen Außen- und Sicherheitspolitik der EU.\n",
      "\n",
      "  found 3 relevant documents\n",
      "\n",
      "SPIEGEL9495-000026 - ['Ein Europa für die Zukunft']\n",
      "Der europäische Einigungsprozeß ist ins Stocken geraten, der Vertrag von Maastricht markiert ein Ende, nicht einen Neubeginn. Er hat die Mitglieder der Europäischen Gemeinschaft gespalten, ihre Bürger in Pro- und Anti-Europäer, die Staaten selbst in Schnellzug- und Bummelzug-Unionisten. Das Wort von...\n",
      "SPIEGEL9495-000074 - ['Skandinavien', 'Arktischer Winter']\n",
      "Mit ihren 20 Kühen im Stall zählen Riitta und Pentti Neitola zu den ganz großen Milchbauern im finnischen Lappland. Steiniger Boden, endlose Kiefern- und Birkenwälder, lange dunkle Winter, die sich schon im September mit Frost und Schnee ankündigen und erst im Mai enden - unter solch unwirtlichen Be...\n",
      "SPIEGEL9495-013599 - ['SPIEGEL-Gespräch', '\"Alle Eier in einen Korb\"', 'Lord Ralf Dahrendorf über die Gefahren der Währungsunion und die\\n  Krise Europas']\n",
      "SPIEGEL: Lord Dahrendorf, der europäische Zug ist schwer ins Schlingern geraten. Streiks gegen die Sparpolitik in Frankreich, Regungen von Mark-Nationalismus in Deutschland - platzt das historische Projekt der Währungsunion? Dahrendorf: Ich glaube nicht, daß es jetzt schon platzt. Aber die Zweifel w...\n",
      "\n",
      "  EXAMPLE 2\n",
      "\n",
      "[98-AH] Filme der Brüder Kaurismäki\n",
      "Suche nach Informationen über Filme, bei denen von mindestens einem der beiden Brüder Aki und Mika Kaurismäki Regie geführt wurde.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-003376 - ['Kino', 'Alles Wodka oder was']\n",
      "Wer sich in der Welt nicht so auskennt, jedenfalls nicht nördlich des Finnischen Meerbusens, muß wissen, daß dort oben in den großen Flaschen, die wie Seltersflaschen aussehen, nicht Wasser ist, sondern Wodka. Man legt den Kopf zurück und setzt die Flasche so steil an, daß es gluckert, und dann lang...\n",
      "\n",
      "  EXAMPLE 3\n",
      "\n",
      "[94-AH] Rückkehr Solschenizyns\n",
      "Finde Dokumente, die über die Rückkehr des Literaturnobelpreisträgers Solschenizyn nach Russland berichten.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-003371 - ['Literatur', 'Laus in den Pelz']\n",
      "Der Fall ist wohl einmalig, in der Geschichte der Literatur wie in der Geschichte staatlicher Herrschaft: Das oberste Entscheidungsorgan einer waffenstarrenden Weltmacht war viele Jahre lang auf die Gedanken und Manuskripte eines Schriftstellers fixiert wie der Exorzist auf den Teufel. Aber dieser A...\n",
      "\n",
      "  EXAMPLE 4\n",
      "\n",
      "[93-AH] Eurofighter\n",
      "Finde Dokumente, die über das Projekt \"Jäger 90\" bzw. den \"Eurofighter\" berichten.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-000018 - ['Rüstung', 'Kampfflieger im Finanzloch']\n",
      "Die Entwicklung des umstrittenen Kampfflugzeugs \"Jäger 90\" wird immer teurer. Zu Beginn des Jahres 1994 klafft eine Finanzierungslücke von vermutlich mehr als einer Milliarde Mark. Der zum Daimler-Imperium gehörende Rüstungskonzern Deutsche Aerospace (Dasa) reichte noch im Dezember beim Bonner Verte...\n",
      "\n",
      "  EXAMPLE 5\n",
      "\n",
      "[103-AH] Interessenkonflikt in Italien\n",
      "Suche Dokumente, die das Problem des Interessenkonflikts des italienischen Premierministers Silvio Berlusconi erörtern.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-003354 - ['Italien', '\"Kann der Teufel Gutes tun?\"', 'Senatspräsident Carlo Scognamiglio über die Aufgaben der Regierung\\n  Berlusconi und den Faschismus']\n",
      "SPIEGEL: Bill Clinton und Helmut Kohl haben Ihrem Ministerpräsidenten Silvio Berlusconi in den vergangenen Wochen gleichsam den Ritterschlag erteilt und ihn als gleichwertigen Partner akzeptiert. Sind damit die Berührungsängste gegenüber der neuen italienischen Regierung überwunden? Scognamiglio: Wi...\n",
      "\n",
      "looking at year 2003\n",
      "\n",
      "  EXAMPLE 0\n",
      "\n",
      "[142-AH] Christo verhüllt den Deutschen Reichstag\n",
      "Finde Berichte über die Verhüllung des Deutschen Reichstages in Berlin durch den Künstler Christo.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-001050 - ['Parlament', 'Signal an die Welt']\n",
      "Für einen schmächtigen älteren Herrn ging es am vergangenen Freitag um alles oder nichts. Wie ein Schuljunge wippte er auf seinem Sitz, fingerte an seinen Kopfhörern und umklammerte angespannt die Armlehnen. Eine gute Stunde Hochspannung durchlebte der bulgarisch-amerikanische Verpackungskünstler Ch...\n",
      "\n",
      "  EXAMPLE 1\n",
      "\n",
      "[156-AH] Gewerkschaften in Europa\n",
      "Welche Unterschiede gibt es hinsichtlich der Rolle und Bedeutung der Gewerkschaften in den europäischen Ländern?\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013639 - ['Weiße Flagge im Kanzleramt', 'Deutschland hat eine Radikalisierung wie in Frankreich vermieden\\n  - durch soziale Partnerschaft']\n",
      "Binnen weniger Tage hat der ramponierte Wirtschaftsstandort Deutschland wieder an Reputation gewonnen. Seit in Frankreich Autos brennen, Tag für Tag Massenstreiks das öffentliche Leben lahmlegen, ist der Angriffsschwung der Sozialabbauer im deutschen Unternehmerlager erlahmt. \"Man kann französische ...\n",
      "\n",
      "  EXAMPLE 2\n",
      "\n",
      "[174-AH] Bayerischer Kruzifixstreit\n",
      "Finde Berichte über den Kruzifixstreit in bayerischen Schulen.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013587 - ['Kruzifixe', 'Ärger im Gericht']\n",
      "Nach Bayerns Schulen haben jetzt auch saarländische Gerichte Ärger mit dem Kruzifix. In Saarbrücken weigerte sich ein Richter, auf Antrag eines Juden das Kruzifix aus dem Gerichtssaal zu entfernen. Der Saarbrücker Gilbert Kallenborn, 41, der sich wegen Überfahrens einer roten Ampel verantworten mußt...\n",
      "\n",
      "  EXAMPLE 3\n",
      "\n",
      "[181-AH] Französische Atomtests\n",
      "Finde Berichte über den internationalen Druck zur Beendigung französischer Atomtests.\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013637 - ['Frankreich', '\"Chirac, die Bombe sind wir\"']\n",
      "Der katastrophale Ausstand im Öffentlichen Dienst, gestand der Pariser Staatschef dem Bonner Kanzler Helmut Kohl beim Treffen im Kurort Baden-Baden vertraulich, könne Frankreichs Europapolitik schwer behindern. Aber, so Chirac vor der Presse an die Kritiker im eigenen Land, nicht der Maastricht-Vert...\n",
      "\n",
      "  EXAMPLE 4\n",
      "\n",
      "[185-AH] Holländische Fotos von Srebrenica\n",
      "Was geschah mit den Fotografien und den Filmen, die holländische Soldaten in Srebrenica aufnahmen und die Beweise für Menschenrechtsverletzungen zeigten?\n",
      "\n",
      "  found 1 relevant documents\n",
      "\n",
      "SPIEGEL9495-013632 - ['Niederlande', 'Nachtwächter für Uno?']\n",
      "Nach der \"Schande von Srebrenica\" - die holländische Uno-Schutztruppe in Bosnien hatte Menschenrechtsverletzungen tatenlos zugesehen - entwickelt die Armeeführung neue Ideen für künftige Missionen. Anstelle von Wehrpflichtigen könne man doch auch Wachmänner privater Sicherheitsdienste als Soldaten e...\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print('\\nlooking at year {}'.format(dataset.year))\n",
    "    for i, (topic_id, docs) in enumerate(true_examples[dataset.year].items()):\n",
    "        print('\\n  EXAMPLE {}\\n'.format(i))\n",
    "        print(dataset.topics[topic_id])\n",
    "        print('  found {} relevant documents\\n'.format(len(docs)))\n",
    "        for doc_id in docs:\n",
    "            print(dataset.docs[doc_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
