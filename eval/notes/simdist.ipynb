{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: loading config from ...ca/ungol-models/conf/logging.conf\n"
     ]
    }
   ],
   "source": [
    "CLR = {\n",
    "    'blue': ['#e0f3ff', '#aadeff', '#2bb1ff', '#15587f', '#0b2c40'],\n",
    "    'gold': ['#fff3dc', '#ffebc7', '#ffddab', '#b59d79', '#5C4938'],\n",
    "    'red':  ['#ffd8e8', '#ff9db6', '#ff3e72', '#6B404C', '#521424'],\n",
    "}\n",
    "\n",
    "from ungol.wmd import wmd\n",
    "from ungol.retrieval import clients\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = pathlib.Path('../../ungol-es/opt')\n",
    "f_codemap = str(basedir / 'src/codemap.bin')\n",
    "f_vocab = str(basedir / 'src/fasttext.de.vocab.pickle')\n",
    "ref = wmd.DocReferences.from_files(f_codemap, f_vocab, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = pathlib.Path('../opt/frozen')\n",
    "\n",
    "f_ungol = 'tmp'\n",
    "f_ungol_exp = 'ungol_reranking_sp_rhwmd.pickle'\n",
    "f_ungol_report = 'ungol_reranking_sp_rhwmd.sum_wmd.pickle'\n",
    "\n",
    "with (folder / f_ungol / f_ungol_report).open('rb') as fd:\n",
    "    report = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q -> d 224500 0.8550819181514476\n",
      "d -> q 3762643 0.7072605539925658\n"
     ]
    }
   ],
   "source": [
    "sims1, sims2 = [], []\n",
    "for dic in report.values():\n",
    "    for sdata in dic.values():\n",
    "        a, b = dict(sdata.local_columns)['sim']\n",
    "        sims1 += list(a)\n",
    "        sims2 += list(b)\n",
    "\n",
    "sims = np.array(sims1), np.array(sims2)\n",
    "\n",
    "print('q -> d', len(sims[0]), sims[0].mean())\n",
    "print('d -> q', len(sims[1]), sims[1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Weighted Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q -> d 224500 0.04998753531776294\n",
      "d -> q 3762643 0.0025698262226867283\n"
     ]
    }
   ],
   "source": [
    "w1, w2 = [], []\n",
    "for dic in report.values():\n",
    "    for sdata in dic.values():\n",
    "        a, b = dict(sdata.local_columns)['weight']\n",
    "        w1 += list(a)\n",
    "        w2 += list(b)\n",
    "\n",
    "w = np.array(w1), np.array(w2)\n",
    "\n",
    "print('q -> d', len(w[0]), w[0].mean())\n",
    "print('d -> q', len(w[1]), w[1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Similarity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rolling_mean(a: np.array, window: int):\n",
    "    assert len(a.shape) == 1\n",
    "    \n",
    "    a_prev = np.repeat(a[0], window // 2)\n",
    "    a_post = np.repeat(a[-1], window // 2 - 1)\n",
    "    \n",
    "    x = np.concatenate((a_prev, a, a_post))\n",
    "    v = np.ones((window, )) / window\n",
    "    \n",
    "    return np.convolve(x, v, mode='valid')\n",
    "\n",
    "def _fig_before(title: str):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Similarity')\n",
    "        ax.set_ylabel('Count')\n",
    "        return fig, ax\n",
    "\n",
    "def _fig_after(fig, ax, patches = None, fname = None):\n",
    "    ax.legend(handles=patches)\n",
    "    \n",
    "    if display:\n",
    "        plt.show(fig)\n",
    "    if fname:\n",
    "        for out_file in [str(out_dir/fname) + s for s in ('.png', '.svg')]:\n",
    "            print('saving to', out_file)\n",
    "            fig.savefig(out_file)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "def _plot(ax, x, data, lim):\n",
    "    color = CLR['blue'][3]\n",
    "    \n",
    "    ax.set_xlim(right=lim)\n",
    "    \n",
    "    smoothed = _rolling_mean(data, 10)\n",
    "    ax.fill_between(x, 0, smoothed, color=color, alpha=0.2)\n",
    "    ax.plot(x, smoothed, color=color, alpha=0.5)\n",
    "    ax.bar(x, data, color=color, alpha=0.7, width=0.00025*len(data)*lim)\n",
    "    \n",
    "for i, name in ((0, 'Similarity Query > Document'), (1, 'Similarity Document > Query')):\n",
    "    data, bin_edges = np.histogram(sims[i], bins=50)\n",
    "    fig, ax = fig_before(name)\n",
    "    _plot(ax, bin_edges[1:], data, lim=1.1)\n",
    "    fig_after(fig, ax)\n",
    "\n",
    "\n",
    "for i, name in ((0, 'IDF Weighted Query > Document'), (1, 'IDF Weighted Document > Query')):\n",
    "    data, bin_edges = np.histogram(w[i], bins=50)\n",
    "    fig, ax = _fig_before(name)\n",
    "    _plot(ax, bin_edges[1:], data, lim=0.2)\n",
    "    _fig_after(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Tokens per Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 268.7602142857143 std 196.32228423825327\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for dic in report.values():\n",
    "    for sdata in dic.values():\n",
    "        _, token = dict(sdata.local_columns)['token']\n",
    "        tokens.append(len(token))\n",
    "\n",
    "a_tokens = np.array(tokens)\n",
    "print('mean', a_tokens.mean(), 'std', a_tokens.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ungol-es",
   "language": "python",
   "name": "ungol-es"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
