{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The definitive guide\n",
    "\n",
    "## Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "import elasticsearch as es\n",
    "e = es.Elasticsearch([{ 'host': 'localhost', 'port': 9200 }])\n",
    "e.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_tweet = {'index': 'tweet', 'doc_type': 'doc'}\n",
    "ctx_user = {'index': 'user', 'doc_type': 'doc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_users = \"\"\"\n",
    "{\"index\": {\"_id\": 1}\n",
    "{\"lang\": \"us\", \"email\": \"john@smith.com\", \"name\": \"John Smith\", \"username\": \"@john\"}\n",
    "{\"index\": {\"_id\": 2}\n",
    "{\"lang\": \"gb\", \"email\": \"mary@jones.com\", \"name\": \"Mary Jones\", \"username\": \"@mary\"}\n",
    "\"\"\"[1:]\n",
    "\n",
    "bulk_tweets = \"\"\"\n",
    "{\"index\": {\"_id\": 3}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-13\", \"name\": \"Mary Jones\", \"tweet\": \"Elasticsearch means full text search has never been so easy\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 4}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-14\", \"name\": \"John Smith\", \"tweet\": \"@mary it is not just text, it does everything\", \"user_id\": 1}\n",
    "{\"index\": {\"_id\": 5}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-15\", \"name\": \"Mary Jones\", \"tweet\": \"However did I manage before Elasticsearch?\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 6}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-16\", \"name\": \"John Smith\", \"tweet\": \"The Elasticsearch API is really easy to use\", \"user_id\": 1}\n",
    "{\"index\": {\"_id\": 7}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-17\", \"name\": \"Mary Jones\", \"tweet\": \"The Query DSL is really powerful and flexible\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 8}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-18\", \"name\": \"John Smith\", \"user_id\": 1}\n",
    "{\"index\": {\"_id\": 9}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-19\", \"name\": \"Mary Jones\", \"tweet\": \"Geo-location aggregations are really cool\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 10}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-20\", \"name\": \"John Smith\", \"tweet\": \"Elasticsearch surely is one of the hottest new NoSQL products\", \"user_id\": 1}\n",
    "{\"index\": {\"_id\": 11}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-21\", \"name\": \"Mary Jones\", \"tweet\": \"Elasticsearch is built for the cloud, easy to scale\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 12}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-22\", \"name\": \"John Smith\", \"tweet\": \"Elasticsearch and I have left the honeymoon stage, and I still love her.\", \"user_id\": 1}\n",
    "{\"index\": {\"_id\": 13}\n",
    "{\"lang\": \"gb\", \"date\": \"2014-09-23\", \"name\": \"Mary Jones\", \"tweet\": \"So yes, I am an Elasticsearch fanboy\", \"user_id\": 2}\n",
    "{\"index\": {\"_id\": 14}\n",
    "{\"lang\": \"us\", \"date\": \"2014-09-24\", \"name\": \"John Smith\", \"tweet\": \"How many more cheesy tweets do I have to write?\", \"user_id\": 1}\n",
    "\"\"\"[1:]\n",
    "\n",
    "def populate_user_index():\n",
    "    print('populating user index')\n",
    "    res = e.bulk(body=bulk_users, **ctx_user)\n",
    "    print('errors:', res['errors'], '- indexed:', len(res['items']))\n",
    "\n",
    "def populate_tweet_index():\n",
    "    print('populating tweet index')\n",
    "    res = e.bulk(body=bulk_tweets, **ctx_tweet)\n",
    "    print('errors:', res['errors'], '- indexed:', len(res['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating user index\n",
      "errors: True - indexed: 2\n",
      "populating tweet index\n",
      "errors: False - indexed: 12\n"
     ]
    }
   ],
   "source": [
    "populate_user_index()\n",
    "populate_tweet_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lite Search\n",
    "\n",
    "* https://www.elastic.co/guide/en/elasticsearch/reference/master/query-dsl-query-string-query.html#query-string-syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 (0.6931472): The Elasticsearch API is really easy to use\n",
      "13 (0.6682933): So yes, I am an Elasticsearch fanboy\n",
      "5 (0.37881336): However did I manage before Elasticsearch?\n",
      "10 (0.35667494): Elasticsearch surely is one of the hottest new NoSQL products\n",
      "12 (0.3034693): Elasticsearch and I have left the honeymoon stage, and I still love her.\n",
      "11 (0.21110918): Elasticsearch is built for the cloud, easy to scale\n",
      "3 (0.16044298): Elasticsearch means full text search has never been so easy\n"
     ]
    }
   ],
   "source": [
    "for hit in e.search(q='tweet:elasticsearch')['hits']['hits']:\n",
    "    print('{} ({}): {}'.format(hit['_id'], hit['_score'], hit['_source']['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': [{'_id': '4',\n",
      "           '_index': 'tweet',\n",
      "           '_score': 0.87546873,\n",
      "           '_source': {'date': '2014-09-14',\n",
      "                       'lang': 'us',\n",
      "                       'name': 'John Smith',\n",
      "                       'tweet': '@mary it is not just text, it does everything',\n",
      "                       'user_id': 1},\n",
      "           '_type': 'doc'}],\n",
      " 'max_score': 0.87546873,\n",
      " 'total': 1}\n"
     ]
    }
   ],
   "source": [
    "pp(e.search(q='+name:john +tweet:mary')['hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_shards': {'failed': 0, 'skipped': 0, 'successful': 33, 'total': 33},\n",
      " 'hits': {'hits': [{'_id': '9',\n",
      "                    '_index': 'tweet',\n",
      "                    '_score': 4.6021132,\n",
      "                    '_source': {'date': '2014-09-19',\n",
      "                                'lang': 'gb',\n",
      "                                'name': 'Mary Jones',\n",
      "                                'tweet': 'Geo-location aggregations are really '\n",
      "                                         'cool',\n",
      "                                'user_id': 2},\n",
      "                    '_type': 'doc'}],\n",
      "          'max_score': 4.6021132,\n",
      "          'total': 1},\n",
      " 'timed_out': False,\n",
      " 'took': 40}\n"
     ]
    }
   ],
   "source": [
    "# name contains 'mary' or 'john'\n",
    "# date is greater than 2014-08-10\n",
    "# _all contains aggregations or geo\n",
    "\n",
    "pp(e.search(q='+name:(mary john) +date:>2014-08-10 +(aggregations geo)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer\n",
    "\n",
    "An analyzer combines three functions:\n",
    "\n",
    "* **Character Filters:** preprocessing which removes markup and replaces symbols\n",
    "* **Tokenizer:** extract terms\n",
    "* **Token Filters:** stemming, synsets etc.\n",
    "\n",
    "Given `Set the shape to semi-transparent by calling set_trans(5)`:\n",
    "\n",
    "* **Standard Analyzer:** `[set, the, shape, to, semi, transparent, by, calling, set_trans, 5]`\n",
    "* **Simple Analyzer:** `[set, the shape, to, semi, transparent, by, calling, set, trans]`\n",
    "* **Whitespace Analyzer** `[Set, the, shape, to, semi-transparent, by, calling, set_trans(5)]`\n",
    "* **Language Analyzer** `[set, shape, semi, transpar, call, set_tran, 5]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': [{'end_offset': 4,\n",
      "             'position': 0,\n",
      "             'start_offset': 0,\n",
      "             'token': 'some',\n",
      "             'type': '<ALPHANUM>'},\n",
      "            {'end_offset': 9,\n",
      "             'position': 1,\n",
      "             'start_offset': 5,\n",
      "             'token': 'text',\n",
      "             'type': '<ALPHANUM>'},\n",
      "            {'end_offset': 13,\n",
      "             'position': 2,\n",
      "             'start_offset': 11,\n",
      "             'token': 'hi',\n",
      "             'type': '<ALPHANUM>'},\n",
      "            {'end_offset': 17,\n",
      "             'position': 3,\n",
      "             'start_offset': 14,\n",
      "             'token': 'mom',\n",
      "             'type': '<ALPHANUM>'}]}\n"
     ]
    }
   ],
   "source": [
    "pp(e.indices.analyze(index='tweet', body={'analyzer': 'standard', 'text': 'Some text, hi Mom!'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping\n",
    "\n",
    "Supported types: `boolean, long, double, date, string, (geo?)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc': {'properties': {'date': {'type': 'date'},\n",
      "                        'lang': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                        'type': 'keyword'}},\n",
      "                                 'type': 'text'},\n",
      "                        'name': {'type': 'text'},\n",
      "                        'tag': {'type': 'keyword'},\n",
      "                        'tweet': {'analyzer': 'english', 'type': 'text'},\n",
      "                        'user_id': {'type': 'long'}}}}\n"
     ]
    }
   ],
   "source": [
    "pp(e.indices.get('tweet')['tweet']['mappings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the mapping of the tweet index manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete index: {'acknowledged': True}\n",
      "re-create index: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'tweet'}\n"
     ]
    }
   ],
   "source": [
    "if e.indices.exists(index='tweet'):\n",
    "    res = e.indices.delete(index='tweet')\n",
    "    print('delete index:', res)\n",
    "\n",
    "tweet_mapping = {\n",
    "    'mappings': {\n",
    "        'doc': {\n",
    "            'properties': {\n",
    "                'tweet': {'type': 'text', 'analyzer': 'english'},\n",
    "                'date': {'type': 'date'},\n",
    "                'name': {'type': 'text'},\n",
    "                'user_id': {'type': 'long'},\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = e.indices.create(index='tweet', body=tweet_mapping)\n",
    "print('re-create index:', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.elastic.co/blog/strings-are-dead-long-live-strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the tag field to type 'keyword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.indices.put_mapping(body={\n",
    "   'properties': {\n",
    "       'tag': {\n",
    "           'type': 'keyword',\n",
    "           'index': 'true',\n",
    "       }\n",
    "   }\n",
    "}, index='tweet', doc_type='doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating tweet index\n",
      "errors: False - indexed: 12\n"
     ]
    }
   ],
   "source": [
    "populate_tweet_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'token': 'black',\n",
       "   'start_offset': 0,\n",
       "   'end_offset': 5,\n",
       "   'type': '<ALPHANUM>',\n",
       "   'position': 0},\n",
       "  {'token': 'cat',\n",
       "   'start_offset': 6,\n",
       "   'end_offset': 10,\n",
       "   'type': '<ALPHANUM>',\n",
       "   'position': 1}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.indices.analyze(body={'field': 'tweet', 'text': 'Black-cats'}, index='tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'token': 'Black-cats',\n",
       "   'start_offset': 0,\n",
       "   'end_offset': 10,\n",
       "   'type': 'word',\n",
       "   'position': 0}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.indices.analyze(body={'field': 'tag', 'text': 'Black-cats'}, index='tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Body Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty Search\n",
    "\n",
    "Also using pagination because the result is very big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 4,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 33, 'successful': 33, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': 142692,\n",
       "  'max_score': 1.0,\n",
       "  'hits': [{'_index': '.monitoring-es-6-2018.05.16',\n",
       "    '_type': 'doc',\n",
       "    '_id': '4e93YLRBRcyShOQN7FSiEA:_na:blog:4:r',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'cluster_uuid': 'O37AcGfuSMe1_i68NGyEPg',\n",
       "     'timestamp': '2018-05-16T06:37:31.673Z',\n",
       "     'interval_ms': 10000,\n",
       "     'type': 'shards',\n",
       "     'source_node': None,\n",
       "     'state_uuid': '4e93YLRBRcyShOQN7FSiEA',\n",
       "     'shard': {'state': 'UNASSIGNED',\n",
       "      'primary': False,\n",
       "      'node': None,\n",
       "      'relocating_node': None,\n",
       "      'shard': 4,\n",
       "      'index': 'blog'}}}]}}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.search(body={'from': 30, 'size': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned results: 144785\n",
      "pagination standard values: from=0, size=10: 10\n",
      "\n",
      "searching for tweets containing \"elasticsearch\":\n",
      "   0 0.6931472 The Elasticsearch API is really easy to use\n",
      "   1 0.6682933 So yes, I am an Elasticsearch fanboy\n",
      "   2 0.37881336 However did I manage before Elasticsearch?\n",
      "   3 0.35667494 Elasticsearch surely is one of the hottest new NoSQL products\n",
      "   4 0.3034693 Elasticsearch and I have left the honeymoon stage, and I still love her.\n",
      "   5 0.21110918 Elasticsearch is built for the cloud, easy to scale\n",
      "   6 0.16044298 Elasticsearch means full text search has never been so easy\n"
     ]
    }
   ],
   "source": [
    "# find mentions with 'match'\n",
    "\n",
    "res = e.search(body={'query': {'match_all': {}}})\n",
    "print('returned results:', res['hits']['total'])\n",
    "\n",
    "hits = res['hits']['hits']\n",
    "print('pagination standard values: from=0, size=10:', len(hits))\n",
    "\n",
    "print('\\nsearching for tweets containing \"elasticsearch\":')\n",
    "res = e.search(body={'query': {'match': {'tweet': 'elasticsearch'}}})\n",
    "for i, hit in enumerate(res['hits']['hits']):\n",
    "    print('  ', i, hit['_score'], hit['_source']['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 0, 'timed_out': False, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}, 'hits': {'total': 0, 'max_score': None, 'hits': []}}\n"
     ]
    }
   ],
   "source": [
    "# example which will not yield results but displays a combination of clauses\n",
    "\n",
    "q = {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'must': {'match': {'tweet': 'elasticsearch'}},\n",
    "            'must_not': {'match': {'name': 'mary'}},\n",
    "            'should': {'match': {'tweet': 'full text'}},\n",
    "            'filter': {'range': {'age': {'gt': 30}}}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = e.search(body=q, index='tweet')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries and Filters\n",
    "\n",
    "https://www.elastic.co/guide/en/elasticsearch/guide/master/_queries_and_filters.html\n",
    "\n",
    "* Filters answer yes|no questions\n",
    "* Queries yield a scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': False,\n",
       " 'error': 'org.elasticsearch.common.ParsingException: no [query] registered for [tweet]'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check validity of a query\n",
    "# (match and tweet are in wrong order)\n",
    "e.indices.validate_query(explain=True, body={\n",
    "    'query': {'tweet': {'match': 'really powerful'}}}, index='tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': True,\n",
       " '_shards': {'total': 1, 'successful': 1, 'failed': 0},\n",
       " 'explanations': [{'index': 'tweet',\n",
       "   'valid': True,\n",
       "   'explanation': 'tweet:realli tweet:power'}]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explanations are nice for valid queries, too\n",
    "e.indices.validate_query(explain=True, body={\n",
    "    'query': {'match': {'tweet': 'really powerful'}}}, index='tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 [1411516800000] 2014-09-24\n",
      "1 1 [1411344000000] 2014-09-22\n",
      "2 1 [1411171200000] 2014-09-20\n",
      "3 1 [1410998400000] 2014-09-18\n",
      "4 1 [1410825600000] 2014-09-16\n",
      "5 1 [1410652800000] 2014-09-14\n"
     ]
    }
   ],
   "source": [
    "# sort tweet of user 1 by recency\n",
    "hits = e.search(body={\n",
    "    'query': {'bool': {'filter': {'term': {'user_id': 1}}}},\n",
    "    'sort': {'date': {'order': 'desc'}}\n",
    "}, index='tweet')['hits']['hits']\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    tweet = hit['_source']\n",
    "    print(i, tweet['user_id'], hit['sort'], tweet['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the tweet field into a multifield mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.indices.put_mapping(body={\n",
    "    'properties': {\n",
    "        'tweet': {\n",
    "            'type': 'text',\n",
    "            'analyzer': 'english',\n",
    "            'fields': {\n",
    "                'raw': {\n",
    "                    'type': 'keyword',\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}, **ctx_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating tweet index\n",
      "errors: False - indexed: 12\n"
     ]
    }
   ],
   "source": [
    "populate_tweet_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Elasticsearch and I have left the honeymoon stage, and I still love her.\n",
      "1 Elasticsearch is built for the cloud, easy to scale\n",
      "2 Elasticsearch means full text search has never been so easy\n",
      "3 Elasticsearch surely is one of the hottest new NoSQL products\n",
      "4 However did I manage before Elasticsearch?\n",
      "5 So yes, I am an Elasticsearch fanboy\n",
      "6 The Elasticsearch API is really easy to use\n"
     ]
    }
   ],
   "source": [
    "hits = e.search(body={\n",
    "    'query': {'match': {'tweet': 'elasticsearch'}},\n",
    "    'sort': 'tweet.raw',\n",
    "}, **ctx_tweet)['hits']['hits']\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    print(i, hit['_source']['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch and I have left the honeymoon stage, and I still love her. \n",
      "\n",
      "{'description': 'weight(tweet:honeymoon in 4) [PerFieldSimilarity], result of:',\n",
      " 'details': [{'description': 'score(doc=4,freq=1.0 = termFreq=1.0\\n'\n",
      "                             '), product of:',\n",
      "              'details': [{'description': 'idf, computed as log(1 + (docCount '\n",
      "                                          '- docFreq + 0.5) / (docFreq + 0.5)) '\n",
      "                                          'from:',\n",
      "                           'details': [{'description': 'docFreq',\n",
      "                                        'details': [],\n",
      "                                        'value': 1.0},\n",
      "                                       {'description': 'docCount',\n",
      "                                        'details': [],\n",
      "                                        'value': 4.0}],\n",
      "                           'value': 1.2039728},\n",
      "                          {'description': 'tfNorm, computed as (freq * (k1 + '\n",
      "                                          '1)) / (freq + k1 * (1 - b + b * '\n",
      "                                          'fieldLength / avgFieldLength)) '\n",
      "                                          'from:',\n",
      "                           'details': [{'description': 'termFreq=1.0',\n",
      "                                        'details': [],\n",
      "                                        'value': 1.0},\n",
      "                                       {'description': 'parameter k1',\n",
      "                                        'details': [],\n",
      "                                        'value': 1.2},\n",
      "                                       {'description': 'parameter b',\n",
      "                                        'details': [],\n",
      "                                        'value': 0.75},\n",
      "                                       {'description': 'avgFieldLength',\n",
      "                                        'details': [],\n",
      "                                        'value': 7.0},\n",
      "                                       {'description': 'fieldLength',\n",
      "                                        'details': [],\n",
      "                                        'value': 10.0}],\n",
      "                           'value': 0.8508287}],\n",
      "              'value': 1.0243746}],\n",
      " 'value': 1.0243746}\n"
     ]
    }
   ],
   "source": [
    "hits = e.search(body={\n",
    "    'query': {'match': {'tweet': 'honeymoon'}}}, explain=True, **ctx_tweet)['hits']['hits']\n",
    "\n",
    "for hit in hits:\n",
    "    print(hit['_source']['tweet'], '\\n')\n",
    "    pp(hit['_explanation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the relevance score $ \\text{score}(\\text{doc}=4, \\text{freq}=1.0) $:\n",
    "\n",
    "### Inverse Document Frequency\n",
    "\n",
    "* $ d_f $ **docFreq** (how many times does the word occur in all documents)\n",
    "* $ d_c $ **docCount** (how many documents are there)\n",
    "\n",
    "$$ \\text{idf}(d_c, d_f) := \\log\\Bigg(1 + \\frac{d_c - d_f + 0.5}{d_f + 0.5}\\Bigg) $$\n",
    "\n",
    "with $ d_f = 1, d_c = 4 $:\n",
    "\n",
    "$$ 1.20397\\dots = \\log\\Bigg(1 + \\frac{4 - 1 + 0.5}{1 + 0.5}\\Bigg) $$\n",
    "\n",
    "### Term Frequency Norm\n",
    "\n",
    "* $ t_f $ - **termFreq** (how many times does the word occur in the document)\n",
    "* $ k^1 $ - **k1** (...)\n",
    "* $ b $ - **b** (...)\n",
    "* $ \\bar{l} $ - **avgFieldLength** (...)\n",
    "* $ l $ - **fieldLength** (...)\n",
    "\n",
    "$$ \\text{tfn}(\\dots) := \\frac{t_f * (k^1 + 1)}{t_f + k^1 \\cdot (1 - b + x)}\\;, \\quad x = b \\cdot \\frac{l}{\\bar{l}} $$\n",
    "\n",
    "with $ t_f = 1, k^1 = 1.2, b = 0.75, \\bar{l} = 7, l = 10 $:\n",
    "\n",
    "$$ 0.85082\\dots = \\frac{1 * (1.2 + 1)}{1 + 1.2 \\cdot (1 - 0.75 + 0.75 \\cdot \\frac{10}{7})} $$\n",
    "\n",
    "### TF-IDF\n",
    "\n",
    "$$ 1.02436\\dots = \\prod_{x \\in \\{\\text{tf}, \\text{idf}\\}} x = 1.2039728 \\cdot 0.8508287 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Example: At index time use synonyms for ***quick***: (***speedy, rapid, fast***). Then at search time, providing one of those suffices. Given document d, containing ***speedy***, with id=4:\n",
    "\n",
    "    INVERTED INDEX:\n",
    "    ...\n",
    "    [quick] = [..., 4]\n",
    "    [speedy] = [..., 4]\n",
    "    [rapid] = [..., 4]\n",
    "    [fast] = [..., 4]\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Relevance Calculation Across Shards\n",
    "\n",
    "The inverse document frequency is not calculated globally over all shards but only locally per shard. This is important to keep in mind if there is not much data. The difference between local and global term frequency counts diminishes with increasing data volume.\n",
    "\n",
    "* https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-is-broken.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
